{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99c4c946",
   "metadata": {},
   "source": [
    "*INE*   \n",
    "*Antonio Coín Castro*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d04832d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-23T18:07:36.546805Z",
     "start_time": "2021-05-23T18:07:36.226260Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbffb514",
   "metadata": {},
   "source": [
    "# Práctica 5 - PageRank y sistemas de recomendación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cc0aa1",
   "metadata": {},
   "source": [
    "## PageRank\n",
    "\n",
    "Calculamos PageRank en el subgrafo web formado por las páginas accesibles desde (e incluyendo) [esta dirección](http://arantxa.ii.uam.es/~abellogin/ir/C.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbde8e5e",
   "metadata": {},
   "source": [
    "### Ejercicio 1.\n",
    "*Tomar r = 0.1, N = nº de páginas en el subgrafo, y 0.3 como valor inicial de PageRank para empezar a iterar.*\n",
    "\n",
    "Consideramos la matriz Google vista en clase:\n",
    "\n",
    "$$\n",
    "G = r\\left(M + \\frac{1}{n}ae^T \\right) + (1-r)\\left( \\frac{1}{n}ee^T\\right),\n",
    "$$\n",
    "\n",
    "donde $M$ es la matriz de hiperenlaces (normalizada por filas), $a$ un vector que contiene un $1$ en la posición $i$-ésima si la fila $i$-ésima de $M$ es nula, y un $0$ si no lo es; y $e$ es un vector de 1s.\n",
    "\n",
    "Después, calculamos el vector de PageRank $\\pi^*$ mediante la fórmula iterativa\n",
    "\n",
    "$$\n",
    "\\pi^{(k+1)T} = \\pi^{(k)T}G.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1605287",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-23T18:07:38.901694Z",
     "start_time": "2021-05-23T18:07:38.882103Z"
    }
   },
   "outputs": [],
   "source": [
    "def iterate_pagerank(M, r, v_init, v_pref=None, normalize=False,\n",
    "                     max_iter=100, eps=1e-4, verbose=False):\n",
    "    n = M.shape[0]\n",
    "    ones = np.ones(n)\n",
    "\n",
    "    if normalize:\n",
    "        v0 = v_init/v_init.sum()\n",
    "    else:\n",
    "        v0 = v_init\n",
    "\n",
    "    # Convert M to G\n",
    "    S = M.copy()\n",
    "    S[S.sum(axis=1) == 0] = n*[1./n]\n",
    "\n",
    "    if v_pref is None:\n",
    "        E = ones.reshape(-1, 1)@ones.reshape(1, -1)/n\n",
    "    else:\n",
    "        E = ones.reshape(-1, 1)@v_pref.reshape(1, -1)\n",
    "\n",
    "    G = r*S + (1 - r)*E\n",
    "\n",
    "    # Iterate PageRank\n",
    "    v_old = v0\n",
    "    if verbose:\n",
    "        print(f\"[Inicial]     v = {v0}\")\n",
    "    for it in range(max_iter):\n",
    "        v_pagerank = v_old.T@G\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"[Iteración {it + 1}] v = {v_pagerank}\")\n",
    "\n",
    "        if np.linalg.norm(v_old - v_pagerank, ord=1) < eps:\n",
    "            break\n",
    "\n",
    "        v_old = v_pagerank\n",
    "\n",
    "    return v_pagerank, it + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34b88e20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T17:49:20.372874Z",
     "start_time": "2021-05-10T17:49:20.355073Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Inicial]     v = [0.3 0.3 0.3 0.3 0.3]\n",
      "[Iteración 1] v = [0.286 0.321 0.306 0.286 0.301]\n",
      "[Iteración 2] v = [0.28662 0.32082 0.30502 0.28662 0.30092]\n",
      "[Iteración 3] v = [0.28658373 0.3208394  0.3050784  0.28658373 0.30091473]\n",
      "[Iteración 4] v = [0.28658607 0.32083745 0.30507516 0.28658607 0.30091525]\n",
      "Converge en 4 iteraciones\n"
     ]
    }
   ],
   "source": [
    "M = np.array([  # hyperlinks matrix\n",
    "    [0, 1/2., 0, 0, 1/2.],      # A\n",
    "    [0, 0, 0, 0, 0],            # B\n",
    "    [1/3., 0, 0, 1/3., 1/3.],   # C\n",
    "    [0, 0, 1., 0, 0],           # D\n",
    "    [0, 1., 0, 0, 0]            # E\n",
    "])\n",
    "r = 0.1\n",
    "n = M.shape[0]\n",
    "v_init = np.full(n, 0.3)\n",
    "\n",
    "pagerank, it = iterate_pagerank(M, r, v_init, verbose=True)\n",
    "print(f\"Converge en {it} iteraciones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f79627e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T17:49:20.384051Z",
     "start_time": "2021-05-10T17:49:20.375794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PageRank\n",
      "PR(A): 0.2866\n",
      "PR(B): 0.3208\n",
      "PR(C): 0.3051\n",
      "PR(D): 0.2866\n",
      "PR(E): 0.3009\n"
     ]
    }
   ],
   "source": [
    "webs = ['A', 'B', 'C', 'D', 'E']\n",
    "print(\"PageRank\")\n",
    "for i, web in enumerate(webs):\n",
    "    print(f\"PR({web}): {pagerank[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c812402f",
   "metadata": {},
   "source": [
    "Un detalle a tener en cuenta es que lo normal es interpretar el vector inicial como una *distribución de probabilidad*, de forma que sus elementos sean no negativos y sumen $1$. Dada la naturaleza del algoritmo, se mantienen estas propiedades en el vector final de PageRank. De esta forma, podemos interpretar este último como el porcentaje de tiempo que un *surfista aleatorio* pasaría en cada una de las páginas consideradas.\n",
    "\n",
    "Damos la opción de normalizar el vector de entrada en el código (vemos que simplemente cambia la escala del resultado final)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4467cd9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T17:49:20.394526Z",
     "start_time": "2021-05-10T17:49:20.386262Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PageRank normalizado\n",
      "PR(A): 0.1911\n",
      "PR(B): 0.2139\n",
      "PR(C): 0.2034\n",
      "PR(D): 0.1911\n",
      "PR(E): 0.2006\n"
     ]
    }
   ],
   "source": [
    "pagerank_norm, it = iterate_pagerank(M, r, v_init, normalize=True)\n",
    "print(\"PageRank normalizado\")\n",
    "for i, web in enumerate(webs):\n",
    "    print(f\"PR({web}): {pagerank_norm[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a322603",
   "metadata": {},
   "source": [
    "### Ejercicio 2.\n",
    "*Con los mismos parámetros del apartado anterior, personalizar PageRank para un usuario que tiene sólo las páginas 'A.html' y 'D.html' entre sus preferencias.*\n",
    "\n",
    "En este caso usamos la propuesta original de Brin & Page, que consiste en modificar la matriz de teleportación $E$ para dejarla como $E=ev^T$, donde $v$ es el *vector de personalización*. Este vector es una distribución de probabilidad que indica las preferencias del usuario de moverse a una u otra página. En el caso de que esta sea la distribución uniforme, recuperamos la matriz $E$ original.\n",
    "\n",
    "En nuestro caso, como el usuario solo tiene preferencia por las páginas A y D (podemos asumir que tiene la misma preferencia por ambas), el vector de personalización es:\n",
    "$$\n",
    "v^T = (1/2, 0, 0, 1/2, 0).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "314e2434",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T17:49:20.408513Z",
     "start_time": "2021-05-10T17:49:20.397434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Inicial]     v = [0.3 0.3 0.3 0.3 0.3]\n",
      "[Iteración 1] v = [0.691 0.051 0.036 0.691 0.031]\n",
      "[Iteración 2] v = [0.67722 0.03867 0.07012 0.67722 0.03677]\n",
      "[Iteración 3] v = [0.67811073 0.0383114  0.0684954  0.67811073 0.03697173]\n",
      "[Iteración 4] v = [0.67804941 0.03836894 0.0685773  0.67804941 0.03695494]\n",
      "[Iteración 5] v = [0.67805329 0.03836534 0.06857232 0.67805329 0.03695576]\n",
      "Converge en 5 iteraciones\n"
     ]
    }
   ],
   "source": [
    "v_pref = np.array([1/2., 0, 0, 1/2., 0])\n",
    "pagerank_pers, it = iterate_pagerank(M, r, v_init, v_pref, verbose=True)\n",
    "print(f\"Converge en {it} iteraciones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b21ebb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T17:49:20.420248Z",
     "start_time": "2021-05-10T17:49:20.411293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PageRank personalizado\n",
      "PR(A): 0.6781\n",
      "PR(B): 0.0384\n",
      "PR(C): 0.0686\n",
      "PR(D): 0.6781\n",
      "PR(E): 0.0370\n"
     ]
    }
   ],
   "source": [
    "webs = ['A', 'B', 'C', 'D', 'E']\n",
    "print(\"PageRank personalizado\")\n",
    "for i, web in enumerate(webs):\n",
    "    print(f\"PR({web}): {pagerank_pers[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1a19f1",
   "metadata": {},
   "source": [
    "### Ejercicio opcional.\n",
    "*Probar valores distintos de r para calcular PageRank.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8289239",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T17:49:20.438314Z",
     "start_time": "2021-05-10T17:49:20.429314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PageRank r=0.0 (converge en 1 iteraciones)\n",
      "PR(A): 0.3000\n",
      "PR(B): 0.3000\n",
      "PR(C): 0.3000\n",
      "PR(D): 0.3000\n",
      "PR(E): 0.3000\n",
      "PageRank r=0.25 (converge en 5 iteraciones)\n",
      "PR(A): 0.2684\n",
      "PR(B): 0.3516\n",
      "PR(C): 0.3097\n",
      "PR(D): 0.2684\n",
      "PR(E): 0.3019\n",
      "PageRank r=0.5 (converge en 8 iteraciones)\n",
      "PR(A): 0.2421\n",
      "PR(B): 0.4020\n",
      "PR(C): 0.3112\n",
      "PR(D): 0.2421\n",
      "PR(E): 0.3026\n",
      "PageRank r=0.75 (converge en 12 iteraciones)\n",
      "PR(A): 0.2196\n",
      "PR(B): 0.4515\n",
      "PR(C): 0.3074\n",
      "PR(D): 0.2196\n",
      "PR(E): 0.3019\n",
      "PageRank r=1.0 (converge en 19 iteraciones)\n",
      "PR(A): 0.2000\n",
      "PR(B): 0.5000\n",
      "PR(C): 0.3000\n",
      "PR(D): 0.2000\n",
      "PR(E): 0.3000\n"
     ]
    }
   ],
   "source": [
    "webs = ['A', 'B', 'C', 'D', 'E']\n",
    "rs = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "\n",
    "for r in rs:\n",
    "    pagerank, it = iterate_pagerank(M, r, v_init)\n",
    "    print(f\"PageRank r={r} (converge en {it} iteraciones)\")\n",
    "    for i, web in enumerate(webs):\n",
    "        print(f\"PR({web}): {pagerank[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ede3d8",
   "metadata": {},
   "source": [
    "Vemos que conforme aumenta el valor de $r$ aumenta el número de iteraciones necesarias para alcanzar la convergencia. Además, con $r=0$ observamos por ejemplo que el PageRank es el mismo para todas las páginas, y conforme aumenta $r$ va aumentando $PR(B)$. Esto no es de extrañar, ya que conforme $r$ aumenta más relevante es la matriz $S$, y en este matriz la columna correspondiente a $B$ es la que tiene la suma más alta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0cddba7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T17:49:20.506736Z",
     "start_time": "2021-05-10T17:49:20.494734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PageRank personalizado r=0.0 (converge en 2 iteraciones)\n",
      "PR(A): 0.7500\n",
      "PR(B): 0.0000\n",
      "PR(C): 0.0000\n",
      "PR(D): 0.7500\n",
      "PR(E): 0.0000\n",
      "PageRank personalizado r=0.25 (converge en 6 iteraciones)\n",
      "PR(A): 0.5800\n",
      "PR(B): 0.1000\n",
      "PR(C): 0.1500\n",
      "PR(D): 0.5800\n",
      "PR(E): 0.0900\n",
      "PageRank personalizado r=0.5 (converge en 9 iteraciones)\n",
      "PR(A): 0.4366\n",
      "PR(B): 0.2161\n",
      "PR(C): 0.2399\n",
      "PR(D): 0.4366\n",
      "PR(E): 0.1707\n",
      "PageRank personalizado r=0.75 (converge en 6 iteraciones)\n",
      "PR(A): 0.3115\n",
      "PR(B): 0.3500\n",
      "PR(C): 0.2861\n",
      "PR(D): 0.3115\n",
      "PR(E): 0.2409\n",
      "PageRank personalizado r=1.0 (converge en 19 iteraciones)\n",
      "PR(A): 0.2000\n",
      "PR(B): 0.5000\n",
      "PR(C): 0.3000\n",
      "PR(D): 0.2000\n",
      "PR(E): 0.3000\n"
     ]
    }
   ],
   "source": [
    "webs = ['A', 'B', 'C', 'D', 'E']\n",
    "rs = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "\n",
    "for r in rs:\n",
    "    pagerank_pers, it = iterate_pagerank(M, r, v_init, v_pref)\n",
    "    print(f\"PageRank personalizado r={r} (converge en {it} iteraciones)\")\n",
    "    for i, web in enumerate(webs):\n",
    "        print(f\"PR({web}): {pagerank_pers[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385f2888",
   "metadata": {},
   "source": [
    "En el caso de personalización también aumenta el número de iteraciones conforme aumenta $r$. Sin embargo, en este caso con $r=0$ el PageRank se reparte únicamente entre las páginas favoritas, mientras que conforme va aumentando $r$ esta preferencia se va disipando poco a poco, llegando con $r=1$ al mismo vector que en el caso uniforme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a77931",
   "metadata": {},
   "source": [
    "## Sistemas de recomendación\n",
    "\n",
    "Usaremos [este dataset](https://docs.google.com/spreadsheets/d/1YmCY-T0ByZRXz8DpaFyieGfsS2jvxsprZr5dsSh8mpE) que se ha obtenido a partir de las puntuaciones que cada estudiante ha otorgado a un total de 150 películas y series. Las puntuaciones se miden en una escala de 1 a 5 con saltos de 0.5 puntos, mientras que 0 significa que la película no se ha visto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cb0077",
   "metadata": {},
   "source": [
    "### Ejercicio 1.\n",
    "\n",
    "*Aplicar un algoritmo de filtrado colaborativo basado en memoria para generar recomendaciones de películas para cada estudiante. La estrategia a usar será a elección de cada estudiante, teniendo en cuenta las consideraciones vistas en clase. Aplicarlo utilizando las puntuaciones de entrenamiento como base para recomendar películas del conjunto de test, y observar el nivel de acierto (visualmente, comparando puntuación real de test y predicción del recomendador).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0aebde3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T17:49:20.693827Z",
     "start_time": "2021-05-10T17:49:20.682239Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\n",
    "    \"data/training-matrix.dat\",\n",
    "    header=0,\n",
    "    sep='\\t'\n",
    ")\n",
    "data_train.fillna(0, inplace=True)\n",
    "X_train = data_train.to_numpy()[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8d3d9b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T17:49:20.708347Z",
     "start_time": "2021-05-10T17:49:20.697471Z"
    }
   },
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(\n",
    "    \"data/test-matrix.dat\",\n",
    "    header=0,\n",
    "    sep='\\t'\n",
    ")\n",
    "data_test.fillna(0, inplace=True)\n",
    "y_test = data_test.to_numpy()[:, 1:]\n",
    "X_test = y_test.copy()\n",
    "X_test[X_test > 0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3fcde6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T17:37:28.429452Z",
     "start_time": "2021-05-09T17:37:28.410192Z"
    }
   },
   "source": [
    "Elegimos hacer k-NN basado en items, es decir, calculamos las predicciones de cada usuario para cada ítem como:\n",
    "\n",
    "$$\n",
    "\\hat r(u, x)= \\sum_{y \\in I(u)\\cap V_k(x)} \\operatorname{sim}(x, y)r(u, y),\n",
    "$$\n",
    "\n",
    "donde $\\operatorname{sim}$ es la similitud entre items, $r$ es la puntuación de un ítem por parte de un usuario (conocida), $I(u)$ son los ítems que ha puntuado el usuario $u$, $V_k(x)$ es el $k$-vecindario (definido por similitud) del ítem $x$, y finalmente\n",
    "\n",
    "$$\n",
    "c=\\frac{1}{\\displaystyle \\sum_{y \\in I(u)\\cap B(x, k)} \\left|\\operatorname{sim}(x, y)\\right|}.\n",
    "$$\n",
    "\n",
    "Como función de similaridad consideramos dos variantes:\n",
    "\n",
    "- *Coseno*:\n",
    "$$\n",
    "\\operatorname{sim}(x, y) = \\cos(r(x), r(y))=\\frac{r(x)r(y)^T}{\\|r(x)\\|r(y)|\\|},\n",
    "$$\n",
    "donde $r(\\cdot) = (r(u_1, \\cdot), \\dots, r(u_N, \\cdot))$ es el vector de recomendaciones de un ítem por parte de todos los usuarios.\n",
    "\n",
    "- *Correlación de Pearson*:\n",
    "$$\n",
    "\\operatorname{sim}(x, y) = \\cos(r(x) - \\bar r(x)e, r(y) - \\bar r(y)e),\n",
    "$$\n",
    "donde $\\bar r(\\cdot)$ es la media de recomendaciones de un ítem, y $e$ es un vector de 1s. Notamos que para un $x$ e $y$ concretos, solo se calcula esta métrica considerando **los usuarios que hayan puntuado ambos ítems**.\n",
    "\n",
    "Desarrollamos una clase que encapsule todo el procesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87181a23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T17:49:20.791479Z",
     "start_time": "2021-05-10T17:49:20.763363Z"
    }
   },
   "outputs": [],
   "source": [
    "class ItemKNN():\n",
    "    def __init__(self, k, similarity='cosine'):\n",
    "        self.k = k\n",
    "        self.similarity = similarity\n",
    "        self.similarity_matrix = None\n",
    "        self.ratings = None\n",
    "        self.neighbours = {}\n",
    "\n",
    "        if self.similarity == 'cosine':\n",
    "            self.sim = self._cosine\n",
    "        else:\n",
    "            self.sim = self._pearson\n",
    "\n",
    "    def _cosine(self, x, y):\n",
    "        rx = self.ratings[x, :]\n",
    "        ry = self.ratings[y, :]\n",
    "        sim = rx@ry/(np.linalg.norm(rx)*np.linalg.norm(ry))\n",
    "        u_xy = (rx*ry > 0).sum()  # number of users that rated x and y\n",
    "        c = u_xy/50\n",
    "        return c*sim\n",
    "\n",
    "    def _pearson(self, x, y):\n",
    "        users_rated_x = self.ratings[x, :] > 0\n",
    "        users_rated_y = self.ratings[y, :] > 0\n",
    "        users_rated_xy = users_rated_x & users_rated_y\n",
    "        u_xy = users_rated_xy.sum()  # number of users that rated x and y\n",
    "\n",
    "        if u_xy > 0:\n",
    "            rx = self.ratings[x, users_rated_xy]\n",
    "            ry = self.ratings[y, users_rated_xy]\n",
    "            rx_centered = rx - np.mean(rx)\n",
    "            ry_centered = ry - np.mean(ry)\n",
    "            if np.linalg.norm(rx_centered)*np.linalg.norm(ry_centered) == 0:\n",
    "                sim = 0  # one of the centered vectors is zero\n",
    "            else:\n",
    "                sim = (rx_centered@ry_centered\n",
    "                       / (np.linalg.norm(rx_centered)*np.linalg.norm(ry_centered)))\n",
    "        else:\n",
    "            sim = 0\n",
    "\n",
    "        c = u_xy/50\n",
    "        return c*sim\n",
    "\n",
    "    def fit(self, X):\n",
    "        n_items = X.shape[0]\n",
    "        self.ratings = X.copy()\n",
    "\n",
    "        # Compute similarity matrix\n",
    "        self.similarity_matrix = np.array(\n",
    "            [[self.sim(x, y)\n",
    "              for x in range(n_items)] for y in range(n_items)])\n",
    "\n",
    "        # Compute all neighbours ordered by similarity\n",
    "        for x in range(X.shape[0]):  # for each item\n",
    "            all_neighbours = self.similarity_matrix[x].argsort()[::-1]\n",
    "            for u in range(X.shape[1]):  # for each user\n",
    "                rated_neighbours = all_neighbours[X[all_neighbours, u] > 0]\n",
    "                self.neighbours[(x, u)] = rated_neighbours[1:self.k + 1]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"X is > 0 in the positions to predict and 0 elsewhere\"\"\"\n",
    "        if self.ratings is None:\n",
    "            raise Exception('Model was not fitted.')\n",
    "\n",
    "        preds = X.T.copy()  # n_users x n_items_rated\n",
    "        for u in range(X.shape[1]):  # for each user\n",
    "            scores_user = X[:, u]\n",
    "            for x in range(X.shape[0]):\n",
    "                item = scores_user[x]\n",
    "                if item == 0:  # only predict non-zero items\n",
    "                    continue\n",
    "\n",
    "                neighbours = self.neighbours[(x, u)]\n",
    "                sim_neighbours = self.similarity_matrix[x, neighbours]\n",
    "                c = np.linalg.norm(sim_neighbours, 1)\n",
    "                pred = (sim_neighbours@self.ratings[neighbours, u]/c\n",
    "                        if c > 0 else np.mean(self.ratings))\n",
    "                preds[u, x] = np.clip(pred, 1, 5)\n",
    "\n",
    "        return preds.T  # n_items_rated x n_users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f81c501",
   "metadata": {},
   "source": [
    "Hacemos una serie de consideraciones sobre el algoritmo implementado:\n",
    "\n",
    "- Por defecto se utiliza la similaridad coseno. En el caso de elegir similaridad Pearson, los valores de $\\bar r(\\cdot)$ se calculan solo sobre los usuarios que han puntuado los ítems involucrados, en lugar de sobre todo el perfil.\n",
    "- Multiplicamos las similitudes $\\operatorname{sim}(x, y)$ por $|U(x)\\cap U(y)|/50$, para penalizar aquellas con poca base de comparación. Recordamos que $U(\\cdot)$ representa el conjunto de usuarios que han puntuado un ítem en concreto.\n",
    "- Si $U(x)\\cap U(y)=\\emptyset$, se establece la similitud correspondiente en $0$.\n",
    "- Para cada ítem y usuario tomamos como conjunto de vecinos los $k$ más similares que además **tengan rating del usuario en cuestión**. Así nos aseguramos que siempre existen vecinos (ya que hay una buena cantidad de ratings en el conjunto de datos).\n",
    "- Si las predicciones se salen de rango, las truncamos a los extremos del intervalo $[1, 5]$. Además, para ítems que tengan similaridad 0 con todos sus vecinos, elegimos establecer la recomendación a la media global de todos los ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0837bc64",
   "metadata": {},
   "source": [
    "Pasamos a entrenar nuestro modelo con la similaridad por defecto. Como tenemos 150 ítems, elegimos como un valor razonable de $k=20$ como tamaño del vecindario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42769b74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T17:49:21.646324Z",
     "start_time": "2021-05-10T17:49:20.887163Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = ItemKNN(k=20)\n",
    "model.fit(X_train)\n",
    "y_hat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3490800",
   "metadata": {},
   "source": [
    "Podemos observar empíricamente la calidad de las predicciones para un par de usuarios al azar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "579fbb2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T17:49:21.658209Z",
     "start_time": "2021-05-10T17:49:21.648919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth usuario 5:\n",
      " [2.  3.  5.  3.  4.  4.  1.  1.  2.  3.5 1.  3.  4.5 2.  3.5 3.  4.5 3.\n",
      " 2. ]\n",
      "Predicciones usuario 5:\n",
      " [3.13207784 3.14668932 3.35850722 3.83260254 3.68483143 3.37117935\n",
      " 3.45395448 3.37220592 3.13635081 3.21074827 2.96162836 3.38481287\n",
      " 3.05848508 3.40221463 2.88398343 3.3457418  3.35797811 3.36776469\n",
      " 3.33648827]\n",
      "\n",
      "Ground truth usuario 10:\n",
      " [3.5 5.  5.  4.5 2.  4.5 5.  4.5 1.  2.  3.5 2.  2.5 1.5 4.5 3. ]\n",
      "Predicciones usuario 10:\n",
      " [3.7659531  3.6225076  3.56259288 3.73992553 3.70631536 3.95134126\n",
      " 4.00707473 3.83532472 3.82513862 3.65803378 3.80952993 3.90194366\n",
      " 3.86902892 3.76169233 3.724872   3.50069905]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "us = [5, 10]\n",
    "for u in us:\n",
    "    gt = y_test[:, u]\n",
    "    preds = y_hat[:, u]\n",
    "    print(f\"Ground truth usuario {u}:\\n\", gt[gt > 0])\n",
    "    print(f\"Predicciones usuario {u}:\\n\", preds[preds > 0])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9833dcfb",
   "metadata": {},
   "source": [
    "Vemos que las predicciones son más o menos acertadas (no difieren en general demasiado de los valores reales), si bien son bastante mejorables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514de2f2",
   "metadata": {},
   "source": [
    "### Ejercicio 2\n",
    "\n",
    "*Calcular el MAE y RMSE de las recomendaciones producidas. Contrastar los resultados (MAE y RMSE) de dos estrategias diferentes de recomendación (o de la misma estrategia con diferentes parámetros).*\n",
    "\n",
    "Las métricas de error MAE (Mean Absolute Error) y RMSE (Root Mean Squared Error) se definen como:\n",
    "\n",
    "$$\n",
    "MAE = \\frac{1}{|R_{test}|}\\sum_{(u, x)\\in R_{test}} |\\hat r(u, x) - r_{test}(u, x)|.\n",
    "$$\n",
    "\n",
    "$$\n",
    "RMSE = \\sqrt{\\frac{1}{|R_{test}|}\\sum_{(u, x)\\in R_{test}} \\left(\\hat r(u, x) - r_{test}(u, x)\\right)^2}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55d8eeac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T17:49:21.673305Z",
     "start_time": "2021-05-10T17:49:21.661710Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_error_metrics(y_hat, y_test):\n",
    "    gt = y_test[y_test > 0].flatten()\n",
    "    preds = y_hat[y_hat > 0].flatten()\n",
    "    R_test = len(gt)\n",
    "\n",
    "    mae = np.linalg.norm(gt - preds, 1)/R_test\n",
    "    mse = np.sqrt(np.linalg.norm(gt - preds, 2)**2/R_test)\n",
    "\n",
    "    return mae, mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ef259c",
   "metadata": {},
   "source": [
    "Estudiamos el error con con varios modelos, aumentando progresivamente el valor de $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1dcc4182",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T17:49:27.291379Z",
     "start_time": "2021-05-10T17:49:21.676282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-NN: MAE = 1.1488, RMSE = 1.5484\n",
      "5-NN: MAE = 0.9671, RMSE = 1.2256\n",
      "10-NN: MAE = 0.9250, RMSE = 1.1644\n",
      "20-NN: MAE = 0.9031, RMSE = 1.1379\n",
      "50-NN: MAE = 0.9063, RMSE = 1.1337\n",
      "75-NN: MAE = 0.9080, RMSE = 1.1291\n",
      "100-NN: MAE = 0.9094, RMSE = 1.1287\n",
      "150-NN: MAE = 0.9099, RMSE = 1.1286\n"
     ]
    }
   ],
   "source": [
    "ks = [1, 5, 10, 20, 50, 75, 100, 150]\n",
    "for k in ks:\n",
    "    model = ItemKNN(k=k)\n",
    "    model.fit(X_train)\n",
    "    y_hat = model.predict(X_test)\n",
    "    mae, rmse = compute_error_metrics(y_hat, y_test)\n",
    "    print(f\"{k}-NN: MAE = {mae:.4f}, RMSE = {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686420f7",
   "metadata": {},
   "source": [
    "Como vemos, un valor de $k=1$ proporciona el mayor error en ambos casos, y el error con $k=5$ es el segundo peor también en ambos casos. Vemos que tomar un vecindario muy grande (100 ó 150 vecinos) hace que disminuya el RMSE, pero sin embargo el MAE desciende más si tomamos un tamaño intermedio (20 ó 50 vecinos).\n",
    "\n",
    "En cuanto al análisis en términos absolutos, como ambos errores se miden en las mismas unidades que los ratings, podemos decir que en media estamos cometiendo un error en torno a $1$ en las predicciones, lo cual dependiendo de la aplicación concreta de nuestro sistema podría o no ser admisible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f9ef66",
   "metadata": {},
   "source": [
    "Finalmente, podemos tomar un par de valores de $k$ y estudiar cómo se comporta el error con la métrica de similaridad basada en el coeficiente de Pearson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8dc3daf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T17:49:32.091186Z",
     "start_time": "2021-05-10T17:49:27.295112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-NN + cosine: MAE = 0.9250, RMSE = 1.1644\n",
      "10-NN + pearson: MAE = 0.9557, RMSE = 1.2291\n",
      "20-NN + cosine: MAE = 0.9031, RMSE = 1.1379\n",
      "20-NN + pearson: MAE = 0.9533, RMSE = 1.2121\n"
     ]
    }
   ],
   "source": [
    "similarity = ['cosine', 'pearson']\n",
    "ks = [10, 20]\n",
    "for k in ks:\n",
    "    for sim in similarity:\n",
    "        model = ItemKNN(k=k, similarity=sim)\n",
    "        model.fit(X_train)\n",
    "        y_hat = model.predict(X_test)\n",
    "        mae, rmse = compute_error_metrics(y_hat, y_test)\n",
    "        print(f\"{k}-NN + {sim}: MAE = {mae:.4f}, RMSE = {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c4b076",
   "metadata": {},
   "source": [
    "Como vemos, el error es en general más alto con la similaridad Pearson."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8387c80",
   "metadata": {},
   "source": [
    "### Ejercicio 3\n",
    "\n",
    "*Calcular P@N (precisión) y R@N (recall) de las recomendaciones producidas a distintos N, considerando como relevantes aquellos ítems con un rating mayor que 3 en test. Para ello, tened en cuenta que habrá que predecir una puntuación (para cada usuario) usando todos los ítems del sistema excepto aquellos que ya ha visto en entrenamiento, ordenando dichas puntuaciones para generar el ranking.*\n",
    "\n",
    "Si $\\mathcal U$ es el conjunto de usuarios, las fórmulas para precisión y recall en este contexto son:\n",
    "\n",
    "$$\n",
    "P@N = \\frac{1}{|\\mathcal U|}\\sum_{u\\in\\mathcal U} \\frac{\\left|Rel_u@N\\right|}{|Rec_u@N|}.\n",
    "$$\n",
    "\n",
    "$$\n",
    "R@N = \\frac{1}{|\\mathcal U|}\\sum_{u\\in\\mathcal U} \\frac{\\left|Rel_u@N\\right|}{\\left| Rel_u\\right|}.\n",
    "$$\n",
    "\n",
    "Fijamos un umbral de 3, y consideramos que un ítem es relevante cuando su rating *verdadero* sea mayor que el umbral. Por otra parte, para obtener las métricas \"@N\", ordenamos las predicciones de los elementos de test según la puntuación predicha, y nos quedamos con las $N$ más altas. Finalmente, notemos que en general $|Rec_u@N|=N$, salvo que no haya suficientes predicciones para ese usuario en concreto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "504eddf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T17:49:32.109545Z",
     "start_time": "2021-05-10T17:49:32.093940Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_precision_recall(y, y_hat, N, threshold=3):\n",
    "    \"\"\"Each column in y_hat must have at least one prediction.\"\"\"\n",
    "    n_items, n_users = y_hat.shape\n",
    "    P_users = np.zeros(n_users)\n",
    "    R_users = np.zeros(n_users)\n",
    "\n",
    "    for u in range(n_users):\n",
    "        user_ratings = [(y_hat[x, u], y[x, u]) for x in range(n_items)]\n",
    "\n",
    "        # Sort user ratings by predicted value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum([true_rating > threshold\n",
    "                     for _, true_rating in user_ratings])\n",
    "\n",
    "        # Number of recommended items in top N\n",
    "        n_rec_N = sum([pred > 0 for pred, _ in user_ratings[:N]])\n",
    "\n",
    "        # Number of relevant items in top N\n",
    "        n_rel_N = sum([true_rating > threshold\n",
    "                       for _, true_rating in user_ratings[:N]])\n",
    "\n",
    "        # Precision@N: Proportion of recommended items that are relevant\n",
    "        P_users[u] = n_rel_N/n_rec_N if n_rec_N != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        R_users[u] = n_rel_N/n_rel if n_rel != 0 else 0\n",
    "\n",
    "    # Average accross all users\n",
    "    P = np.mean(P_users)\n",
    "    R = np.mean(R_users)\n",
    "\n",
    "    return P, R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b8fb6d",
   "metadata": {},
   "source": [
    "Elegimos por ejemplo $k=20$ en el modelo, y calculamos las métricas $P$, $R$ y $F$ (media armónica) a distintos valores de $N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31af2231",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T17:49:32.827637Z",
     "start_time": "2021-05-10T17:49:32.112604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@1: 0.6897, R@1: 0.0739, F@1: 0.1335\n",
      "P@3: 0.6897, R@3: 0.2174, F@3: 0.3306\n",
      "P@5: 0.6621, R@5: 0.3288, F@5: 0.4394\n",
      "P@10: 0.6363, R@10: 0.6193, F@10: 0.6277\n",
      "P@25: 0.6198, R@25: 0.9918, F@25: 0.7629\n",
      "P@50: 0.6179, R@50: 1.0000, F@50: 0.7638\n",
      "P@100: 0.6179, R@100: 1.0000, F@100: 0.7638\n"
     ]
    }
   ],
   "source": [
    "model = ItemKNN(k=20)\n",
    "model.fit(X_train)\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "Ns = [1, 3, 5, 10, 25, 50, 100]\n",
    "for N in Ns:\n",
    "    P, R = compute_precision_recall(y_test, y_hat, N, threshold=3)\n",
    "    F = 2*P*R/(P + R) if P + R > 0 else 0\n",
    "    print(f\"P@{N}: {P:.4f}, R@{N}: {R:.4f}, F@{N}: {F:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714b7914",
   "metadata": {},
   "source": [
    "Observamos que la precisión desciende conforme aumenta el valor de $N$, aunque no de forma demasiado brusca. Además, parece que se estabiliza a partir de $N=25$ en un valor en torno a $0.62$.\n",
    "\n",
    "En cuanto al recall, tiene el comportamiento opuesto: aumenta conforme aumentamos $N$. En este caso a partir de $N=25$ también se estabiliza en un valor de $1$. Esto se puede explicar observando que de media hay menos de 25 ítems relevantes (con puntuación mayor que 3) por cada usuario.\n",
    "\n",
    "Aunque los mejores resultados en la métrica $F$ se obtengan con valores grandes de $N$, el valor de $F@10$ no es del todo malo, por lo que podemos decir que tenemos un recomendador top-10 decente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8533e1",
   "metadata": {},
   "source": [
    "Podemos probar como hicimos anteriormente a elegir un par de valores de $k$ y calcular la precisión y el recall para las dos métricas de similaridad consideradas. Estudiamos por ejemplo P@10 y R@10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f93643b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T17:49:37.684676Z",
     "start_time": "2021-05-10T17:49:32.832592Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-NN + cosine --> P@10: 0.6156, R@10: 0.5961, F@10: 0.6057\n",
      "10-NN + pearson --> P@10: 0.6329, R@10: 0.6140, F@10: 0.6233\n",
      "20-NN + cosine --> P@10: 0.6363, R@10: 0.6193, F@10: 0.6277\n",
      "20-NN + pearson --> P@10: 0.6398, R@10: 0.6212, F@10: 0.6303\n"
     ]
    }
   ],
   "source": [
    "similarity = ['cosine', 'pearson']\n",
    "ks = [10, 20]\n",
    "for k in ks:\n",
    "    for sim in similarity:\n",
    "        model = ItemKNN(k=k, similarity=sim)\n",
    "        model.fit(X_train)\n",
    "        y_hat = model.predict(X_test)\n",
    "        P, R = compute_precision_recall(y_test, y_hat, 10, threshold=3)\n",
    "        F = 2*P*R/(P + R) if P + R > 0 else 0\n",
    "        print(f\"{k}-NN + {sim} --> P@10: {P:.4f}, R@10: {R:.4f}, F@10: {F:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ec7616",
   "metadata": {},
   "source": [
    "En este caso sucede al revés que con el MAE y el RMSE: obtenemos unos mejores resultados de evaluación con la métrica de Pearson."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be15ec58",
   "metadata": {},
   "source": [
    "### Ejercicio opcional (1)\n",
    "\n",
    "*Utilizar librerías (por ejemplo, Mahout, RankSys, LibRec o LensKit en Java, MyMediaLite en C#, Surprise, LightFM o Elliot en Python, recommenderlab en R, u otra) sobre los mismos datos para generar las recomendaciones y comparar con los resultados anteriores. Contrastar los valores de MAE y RMSE de las diferentes pruebas.*\n",
    "\n",
    "Para hacer este ejercicio he elegido la librería [Surprise](https://surprise.readthedocs.io/en/latest/) de Python. \n",
    "\n",
    "En primer lugar, cargamos los datos en el formato de columnas que acepta Surprise, pasándolos por un dataframe de Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7088634",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T17:49:37.944997Z",
     "start_time": "2021-05-10T17:49:37.688439Z"
    }
   },
   "outputs": [],
   "source": [
    "from surprise import NormalPredictor\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "\n",
    "# Creation of the dataframes. Column names are irrelevant.\n",
    "df_train = pd.read_csv(\n",
    "    \"data/training-ratings.dat\",\n",
    "    sep='\\t',\n",
    "    names=['userID', 'itemID', 'rating']\n",
    ")\n",
    "df_test = pd.read_csv(\n",
    "    \"data/test-ratings.dat\",\n",
    "    sep='\\t',\n",
    "    names=['userID', 'itemID', 'rating']\n",
    ")\n",
    "\n",
    "# A reader is still needed but only the rating_scale param is requiered.\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "trainset = Dataset.load_from_df(df_train, reader).build_full_trainset()\n",
    "testset = Dataset.load_from_df(\n",
    "    df_test, reader).build_full_trainset().build_testset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b96cf33",
   "metadata": {},
   "source": [
    "Utilizamos el conjunto de entrenamiento para entrenar y el de test para predecir, calculando las métricas de MAE y RMSE. Utilizamos tanto la similaridad coseno como la similaridad Pearson, y fijamos el valor de $k=20$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53298a67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T17:49:38.142450Z",
     "start_time": "2021-05-10T17:49:37.947381Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "-- Cosine --\n",
      "MAE:  0.8686\n",
      "RMSE: 1.0794\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "-- Pearson --\n",
      "MAE:  0.8970\n",
      "RMSE: 1.1023\n"
     ]
    }
   ],
   "source": [
    "from surprise import accuracy\n",
    "from surprise.prediction_algorithms.knns import KNNBasic\n",
    "\n",
    "cosine_sim = {\n",
    "    'name': 'cosine',\n",
    "    'user_based': False  # compute similarities between items\n",
    "}\n",
    "pearson_sim = {\n",
    "    'name': 'pearson',\n",
    "    'user_based': False  # compute similarities between items\n",
    "}\n",
    "\n",
    "algorithms = [\n",
    "    (\"Cosine\", KNNBasic(k=20, sim_options=cosine_sim)),\n",
    "    (\"Pearson\", KNNBasic(k=20, sim_options=pearson_sim))\n",
    "]\n",
    "\n",
    "for name, alg in algorithms:\n",
    "    # Train the algorithm on the trainset, and predict ratings for the testset\n",
    "    alg.fit(trainset)\n",
    "    print(f\"-- {name} --\")\n",
    "    predictions = alg.test(testset)\n",
    "\n",
    "    # Then compute error and evaluation metrics\n",
    "    mae = accuracy.mae(predictions)\n",
    "    rmse = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e9deb0",
   "metadata": {},
   "source": [
    "Si recordamos nuestras puntuaciones al programar nosotros el algoritmo, vemos que están relativamente cerca de estos valores (sobre todo en el caso del coseno). Por tanto, podemos decir que nuestro algoritmo funciona bastante bien."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e5fff9",
   "metadata": {},
   "source": [
    "### Ejercicio opcional (2)\n",
    "\n",
    "*Repetir alguno de los ejercicios anteriores con alguna colección de prueba (p.e., MovieLens).*\n",
    "\n",
    "Repetimos el ejercicio opcional (1) con la colección [MovieLens](https://grouplens.org/datasets/movielens/), que ya viene integrada en el paquete Surprise. Para ilustrar los resultados utilizamos la versión con 100k ratings. Además, en vez de separar manualmente los conjuntos de entrenamiento y test, hacemos 5-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94a6b8c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T17:50:20.516908Z",
     "start_time": "2021-05-10T17:49:38.145793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Cosine --- \n",
      "Evaluating MAE, RMSE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "MAE (testset)     0.8334  0.8302  0.8327  0.8258  0.8257  0.8296  0.0033  \n",
      "RMSE (testset)    1.0520  1.0498  1.0523  1.0475  1.0417  1.0487  0.0039  \n",
      "Fit time          5.15    4.38    4.79    4.75    3.29    4.47    0.64    \n",
      "Test time         7.69    8.98    8.46    8.60    4.74    7.69    1.53    \n",
      "--- Pearson --- \n",
      "Evaluating MAE, RMSE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "MAE (testset)     0.8556  0.8553  0.8549  0.8608  0.8564  0.8566  0.0021  \n",
      "RMSE (testset)    1.0628  1.0664  1.0651  1.0755  1.0684  1.0676  0.0043  \n",
      "Fit time          5.93    5.56    5.64    5.61    2.71    5.09    1.20    \n",
      "Test time         6.34    6.41    6.56    6.37    2.42    5.62    1.60    \n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# Load the movielens-100k dataset (download it if needed),\n",
    "movielens = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "for name, alg in algorithms:\n",
    "    print(f\"--- {name} --- \")\n",
    "    # Run 5-fold cross-validation and print results\n",
    "    cross_validate(alg, movielens, n_jobs=-1, \n",
    "                   measures=['MAE', 'RMSE'], cv=5, \n",
    "                   verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefb8f3c",
   "metadata": {},
   "source": [
    "En este caso vemos que para ambas métricas obtenemos unos errores medios de CV más pequeños que los que teníamos con nuestro pequeño conjunto de prueba."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": false,
   "autoclose": true,
   "autocomplete": false,
   "bibliofile": "bibliography.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
